{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Energy Prediction with Quantile Loss for Uncertainty Quantification (Online Adaptation)\n",
    "\n",
    "- Uses TensorFlow/Keras for LSTM modeling.\n",
    "- Implements Quantile Loss to estimate prediction intervals.\n",
    "- Adapts the structure for potential online prediction within a BMS context (predicting one step ahead based on recent history)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to data files (Ensure these files are in the same directory)\n",
    "EPW_FILE = \"Torino_IT-hour.epw\"\n",
    "SIM_FILE = \"eplusout.csv\"\n",
    "\n",
    "# Create output directory for plots\n",
    "os.makedirs(\"output_lstm\", exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "N_LAG = 24  # Use past 24 hours to predict the next hour\n",
    "SPLIT_RATIO = 0.8\n",
    "EPOCHS = 50 # Adjust as needed\n",
    "BATCH_SIZE = 64\n",
    "QUANTILES = [0.1, 0.5, 0.9] # For 80% prediction interval (0.1 to 0.9) and median (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and preprocessing data...\")\n",
    "\n",
    "# Load EPW weather data\n",
    "try:\n",
    "    epw = pd.read_csv(EPW_FILE, skiprows=8, header=None)\n",
    "    epw.columns = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"DataSource\", \"DryBulb\", \"DewPoint\", \"RH\", \"AtmosPressure\", \n",
    "                   \"ExtGlobHorRad\", \"ExtDirNormRad\", \"ExtDifHorRad\", \"GlobalHorRad\", \"DirectNormRad\", \n",
    "                   \"DiffuseHorRad\", \"InfraSky\", \"WindDir\", \"WindSpd\", \"TotalSkyCover\", \"OpaqueSkyCover\", \n",
    "                   \"Visibility\", \"CeilingHeight\", \"PresWeatherObs\", \"PresWeatherCodes\", \"PrecipWater\", \"AerosolOptDepth\",\n",
    "                   \"SnowDepth\", \"DaysSinceSnow\", \"Albedo\", \"LiquidPrecip\", \"RainRate\", \"RainDuration\", \"SnowRate\", \"SnowDuration\"]\n",
    "    # Select relevant weather features\n",
    "    weather_df = epw[[\"DryBulb\", \"RH\", \"ExtDirNormRad\", \"ExtDifHorRad\"]].copy()\n",
    "    weather_df.columns = [\"Temperature\", \"Humidity\", \"DirectRad\", \"DiffuseRad\"]\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: EPW file not found at {EPW_FILE}\")\n",
    "    # Handle error appropriately, e.g., exit or use dummy data\n",
    "    exit()\n",
    "\n",
    "# Load simulation output data\n",
    "try:\n",
    "    sim_df = pd.read_csv(SIM_FILE, low_memory=False)\n",
    "    # Select the same target column as before\n",
    "    target_col = \"BLOCCO1:ZONA3:Zone Total Internal Latent Gain Energy [J](TimeStep)\"\n",
    "    if target_col not in sim_df.columns:\n",
    "        print(f\"Error: Target column \\t{target_col}\\t not found in {SIM_FILE}\")\n",
    "        # Try finding a similar column or exit\n",
    "        energy_cols = [c for c in sim_df.columns if \"Energy\" in c and \"Latent\" in c]\n",
    "        if energy_cols:\n",
    "            target_col = energy_cols[0] # Use the first found column as a fallback\n",
    "            print(f\"Using fallback target column: {target_col}\")\n",
    "        else:\n",
    "            print(\"No suitable energy column found. Exiting.\")\n",
    "            exit()\n",
    "\n",
    "    sim_df_hourly = sim_df[[target_col]].copy()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Simulation file not found at {SIM_FILE}\")\n",
    "    exit()\n",
    "\n",
    "# Combine weather and simulation data\n",
    "weather_df_reset = weather_df.reset_index(drop=True)\n",
    "sim_df_hourly_reset = sim_df_hourly.reset_index(drop=True)\n",
    "min_length = min(len(weather_df_reset), len(sim_df_hourly_reset))\n",
    "weather_df_reset = weather_df_reset.iloc[:min_length]\n",
    "sim_df_hourly_reset = sim_df_hourly_reset.iloc[:min_length]\n",
    "full_df = pd.concat([weather_df_reset, sim_df_hourly_reset], axis=1).dropna()\n",
    "\n",
    "print(f\"Combined dataset shape: {full_df.shape}\")\n",
    "print(\"Selected features: [Temperature, Humidity, DirectRad, DiffuseRad]\")\n",
    "print(f\"Selected target: {target_col}\")\n",
    "print(full_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling and Sequence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "features = full_df[[\"Temperature\", \"Humidity\", \"DirectRad\", \"DiffuseRad\"]].values\n",
    "target = full_df[target_col].values\n",
    "\n",
    "# Normalize data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(features)\n",
    "Y_scaled = scaler_Y.fit_transform(target.reshape(-1, 1))\n",
    "\n",
    "# Create time sequences\n",
    "X_seq, Y_seq = [], []\n",
    "for i in range(N_LAG, len(X_scaled)):\n",
    "    X_seq.append(X_scaled[i - N_LAG:i])\n",
    "    Y_seq.append(Y_scaled[i])\n",
    "\n",
    "X_seq = np.array(X_seq)\n",
    "Y_seq = np.array(Y_seq)\n",
    "\n",
    "print(f\"Shape of sequence data: X={X_seq.shape}, Y={Y_seq.shape}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "split_idx = int(SPLIT_RATIO * len(X_seq))\n",
    "X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]\n",
    "Y_train, Y_test = Y_seq[:split_idx], Y_seq[split_idx:]\n",
    "\n",
    "print(f\"Training data shape: X={X_train.shape}, Y={Y_train.shape}\")\n",
    "print(f\"Testing data shape: X={X_test.shape}, Y={Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM Model with Quantile Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Quantile Loss function\n",
    "def quantile_loss(q, y_true, y_pred):\n",
    "    e = y_true - y_pred\n",
    "    return keras.backend.mean(keras.backend.maximum(q * e, (q - 1) * e), axis=-1)\n",
    "\n",
    "# Build the LSTM model\n",
    "def build_lstm_quantile_model(n_timesteps, n_features, n_quantiles):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.LSTM(50, activation=\"relu\", input_shape=(n_timesteps, n_features), return_sequences=True))\n",
    "    model.add(layers.LSTM(50, activation=\"relu\"))\n",
    "    model.add(layers.Dense(50, activation=\"relu\"))\n",
    "    model.add(layers.Dense(n_quantiles)) # Output layer predicts all quantiles\n",
    "    return model\n",
    "\n",
    "# Instantiate the model\n",
    "n_features = X_train.shape[2]\n",
    "n_quantiles = len(QUANTILES)\n",
    "lstm_model = build_lstm_quantile_model(N_LAG, n_features, n_quantiles)\n",
    "\n",
    "# Compile the model with quantile losses for each output\n",
    "losses = [lambda y_true, y_pred: quantile_loss(q, y_true, y_pred) for q in QUANTILES]\n",
    "lstm_model.compile(optimizer=\"adam\", loss=losses)\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training LSTM model...\")\n",
    "\n",
    "# Since the model predicts all quantiles, but the loss needs to compare against the single true value,\n",
    "# we need to provide the true value replicated for each quantile output during training.\n",
    "# However, Keras handles this implicitly when a list of losses is provided for a single output tensor.\n",
    "# We just need to ensure Y_train is the correct shape (samples, 1).\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    X_train,\n",
    "    Y_train, \n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2, # Use part of training data for validation\n",
    "    verbose=1, # Set to 1 or 2 to see progress\n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)] # Early stopping\n",
    ")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"LSTM Model Training History\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"output_lstm/training_history.png\")\n",
    "# plt.show() # Avoid showing plot in non-interactive execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model and Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating model on test data...\")\n",
    "\n",
    "# Predict quantiles on the test set\n",
    "Y_pred_quantiles_scaled = lstm_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and the true values\n",
    "Y_pred_quantiles = scaler_Y.inverse_transform(Y_pred_quantiles_scaled)\n",
    "Y_test_actual = scaler_Y.inverse_transform(Y_test)\n",
    "\n",
    "# Extract lower, median, and upper predictions\n",
    "# Assuming QUANTILES = [0.1, 0.5, 0.9]\n",
    "Y_pred_lower = Y_pred_quantiles[:, 0]\n",
    "Y_pred_median = Y_pred_quantiles[:, 1]\n",
    "Y_pred_upper = Y_pred_quantiles[:, 2]\n",
    "\n",
    "# Calculate metrics using the median prediction\n",
    "mae = mean_absolute_error(Y_test_actual, Y_pred_median)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test_actual, Y_pred_median))\n",
    "\n",
    "print(f\"Test MAE (Median Prediction): {mae:.2f}\")\n",
    "print(f\"Test RMSE (Median Prediction): {rmse:.2f}\")\n",
    "\n",
    "# Visualize predictions with uncertainty bounds\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(Y_test_actual, label=\"True Energy\", color=\"black\")\n",
    "plt.plot(Y_pred_median, label=\"Predicted Median (q=0.5)\", color=\"purple\")\n",
    "plt.fill_between(range(len(Y_test_actual)), Y_pred_lower, Y_pred_upper, color=\"purple\", alpha=0.2, label=\"80% Prediction Interval (q=0.1 to 0.9)\")\n",
    "plt.title(\"LSTM Energy Prediction with Uncertainty (Quantile Regression)\")\n",
    "plt.xlabel(\"Time Step (Hour)\")\n",
    "plt.ylabel(\"Energy (J)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"output_lstm/prediction_vs_actual_quantile.png\")\n",
    "# plt.show() # Avoid showing plot in non-interactive execution\n",
    "\n",
    "# Visualize first 100 hours for clarity\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(Y_test_actual[:100], label=\"True Energy\", color=\"black\")\n",
    "plt.plot(Y_pred_median[:100], label=\"Predicted Median (q=0.5)\", color=\"purple\")\n",
    "plt.fill_between(range(100), Y_pred_lower[:100], Y_pred_upper[:100], color=\"purple\", alpha=0.2, label=\"80% Prediction Interval (q=0.1 to 0.9)\")\n",
    "plt.title(\"LSTM Energy Prediction - First 100 Hours\")\n",
    "plt.xlabel(\"Time Step (Hour)\")\n",
    "plt.ylabel(\"Energy (J)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"output_lstm/prediction_vs_actual_quantile_100h.png\")\n",
    "# plt.show() # Avoid showing plot in non-interactive execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Adaptation for Online Prediction (Conceptual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and scalers for online use\n",
    "lstm_model.save(\"lstm_energy_predictor.keras\")\n",
    "import joblib\n",
    "joblib.dump(scaler_X, \"scaler_X.joblib\")\n",
    "joblib.dump(scaler_Y, \"scaler_Y.joblib\")\n",
    "\n",
    "print(\"Model and scalers saved.\")\n",
    "\n",
    "# --- Function for Online Prediction ---\n",
    "\n",
    "def predict_next_step(model, scaler_x, scaler_y, recent_data_sequence):\n",
    "    \"\"\"\n",
    "    Predicts the next energy step based on a sequence of recent data.\n",
    "    \n",
    "    Args:\n",
    "        model (keras.Model): The trained LSTM model.\n",
    "        scaler_x (MinMaxScaler): The fitted scaler for input features.\n",
    "        scaler_y (MinMaxScaler): The fitted scaler for the target variable.\n",
    "        recent_data_sequence (np.array): Array of recent feature data \n",
    "                                        with shape (N_LAG, n_features).\n",
    "                                        Data should be in original scale.\n",
    "                                        Example: [[temp1, hum1, rad1, dif1], ... , [tempN, humN, radN, difN]]\n",
    "                                        where N = N_LAG.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the predicted quantiles in original scale.\n",
    "              e.g., {\"lower\": float, \"median\": float, \"upper\": float}\n",
    "    \"\"\"\n",
    "    if recent_data_sequence.shape != (N_LAG, n_features):\n",
    "        raise ValueError(f\"Input sequence must have shape ({N_LAG}, {n_features})\")\n",
    "    \n",
    "    # Scale the input sequence\n",
    "    input_scaled = scaler_x.transform(recent_data_sequence)\n",
    "    \n",
    "    # Reshape for LSTM input (1 sample, N_LAG steps, n_features)\n",
    "    input_reshaped = input_scaled.reshape(1, N_LAG, n_features)\n",
    "    \n",
    "    # Predict scaled quantiles\n",
    "    pred_scaled = model.predict(input_reshaped)[0] # Get the first (only) prediction\n",
    "    \n",
    "    # Inverse transform to original scale\n",
    "    pred_original = scaler_y.inverse_transform(pred_scaled.reshape(1, -1))[0]\n",
    "    \n",
    "    # Return as a dictionary (assuming QUANTILES = [0.1, 0.5, 0.9])\n",
    "    return {\n",
    "        \"lower\": pred_original[0],\n",
    "        \"median\": pred_original[1],\n",
    "        \"upper\": pred_original[2]\n",
    "    }\n",
    "\n",
    "# Example usage (conceptual - requires actual recent data)\n",
    "# recent_data = np.random.rand(N_LAG, n_features) * 50 # Replace with actual data\n",
    "# prediction = predict_next_step(lstm_model, scaler_X, scaler_Y, recent_data)\n",
    "# print(f\"Example Prediction: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

